Dolly v2-7b is a 6.9 billion parameter language model created by Databricks, based on EleutherAI's Pythia-6.9b architecture. It has been fine-tuned on approximately 15,000 instruction/response pairs generated by Databricks employees. This model is designed for instruction-following tasks and is licensed for commercial use.

The model's primary usage is to follow instructions and generate text responses. It can be accessed using the transformers library and the pipeline function.

However, it's important to note that Dolly v2-7b is not considered a state-of-the-art model. While it excels at instruction following, it may not perform as competitively as more modern models in other tasks. The model has limitations, including struggling with complex prompts, programming tasks, mathematical operations, and open-ended questions.


> The above summary was generated using ChatGPT. Review the <a href="https://huggingface.co/databricks/dolly-v2-7b" target="_blank">original model card</a> to understand the data used to train the model, evaluation metrics, license, intended uses, limitations and bias before using the model.

### Inference samples

Inference type|Python sample (Notebook)|CLI with YAML
|--|--|--|
Real time|<a href="https://aka.ms/azureml-infer-online-sdk-text-generation-dolly" target="_blank">text-generation-online-endpoint-dolly.ipynb</a>|<a href="https://aka.ms/azureml-infer-online-cli-text-generation-dolly" target="_blank">text-generation-online-endpoint-dolly.sh</a>
Batch |<a href="https://aka.ms/azureml-infer-batch-sdk-text-generation" target="_blank">text-generation-batch-endpoint.ipynb</a>| coming soon


### Model Evaluation

Task| Use case| Dataset| Python sample (Notebook)| CLI with YAML
|--|--|--|--|--|
Text generation | Text generation | <a href="https://huggingface.co/datasets/cnn_dailymail" target="_blank"> cnn_dailymail </a> | <a href="https://aka.ms/azureml-eval-sdk-text-generation/" target="_blank">evaluate-model-text-generation.ipynb</a> | <a href="https://aka.ms/azureml-eval-cli-text-generation/" target="_blank">evaluate-model-text-generation.yml</a>


### Finetuning samples

Task|Use case|Dataset|Python sample (Notebook)|CLI with YAML
|--|--|--|--|--|
Text Classification|Emotion Detection|<a href="https://huggingface.co/datasets/dair-ai/emotion" target="_blank">Emotion</a>|<a href="https://aka.ms/azureml-ft-sdk-emotion-detection" target="_blank">emotion-detection.ipynb</a>|<a href="https://aka.ms/azureml-ft-cli-emotion-detection" target="_blank">emotion-detection.sh</a>


### Sample inputs and outputs (for real-time inference)

```json
{
    "input_data": {
        "input_string": ["My name is John and I am", "Once upon a time,"]
    }
}
```

#### Sample output
```json
[
    {
        "0": "I am John and I am studying Data Science at UNSW."
    }, 
    {
        "0": "There was a little girl named Mary who loved Christmas. She wanted the world to know that she was special."
    }
]
```
