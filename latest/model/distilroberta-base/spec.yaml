$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json
name: distilroberta-base
path: ./
properties:
  SHA: d5411c3ee9e1793fd9ef58390b40a80a4c10df32
  datasets: openwebtext
  evaluation-min-sku-spec: 8|0|28|56
  evaluation-recommended-sku: Standard_DS4_v2
  finetune-min-sku-spec: 4|1|28|176
  finetune-recommended-sku: Standard_NC24rs_v3
  finetuning-tasks: text-classification, token-classification, question-answering
  inference-min-sku-spec: 2|0|7|14
  inference-recommended-sku: Standard_DS2_v2, Standard_D2a_v4, Standard_D2as_v4, Standard_DS3_v2,
    Standard_D4a_v4, Standard_D4as_v4, Standard_DS4_v2, Standard_D8a_v4, Standard_D8as_v4,
    Standard_DS5_v2, Standard_D16a_v4, Standard_D16as_v4, Standard_D32a_v4, Standard_D32as_v4,
    Standard_D48a_v4, Standard_D48as_v4, Standard_D64a_v4, Standard_D64as_v4, Standard_D96a_v4,
    Standard_D96as_v4, Standard_F4s_v2, Standard_FX4mds, Standard_F8s_v2, Standard_FX12mds,
    Standard_F16s_v2, Standard_F32s_v2, Standard_F48s_v2, Standard_F64s_v2, Standard_F72s_v2,
    Standard_FX24mds, Standard_FX36mds, Standard_FX48mds, Standard_E2s_v3, Standard_E4s_v3,
    Standard_E8s_v3, Standard_E16s_v3, Standard_E32s_v3, Standard_E48s_v3, Standard_E64s_v3,
    Standard_NC4as_T4_v3, Standard_NC6s_v3, Standard_NC8as_T4_v3, Standard_NC12s_v3,
    Standard_NC16as_T4_v3, Standard_NC24s_v3, Standard_NC64as_T4_v3, Standard_NC24ads_A100_v4,
    Standard_NC48ads_A100_v4, Standard_NC96ads_A100_v4, Standard_ND96asr_v4, Standard_ND96amsr_A100_v4,
    Standard_ND40rs_v2
  languages: en
tags:
  Preview: ''
  computes_allow_list:
  - Standard_NV12s_v3
  - Standard_NV24s_v3
  - Standard_NV48s_v3
  - Standard_NC6s_v3
  - Standard_NC12s_v3
  - Standard_NC24s_v3
  - Standard_NC24rs_v3
  - Standard_NC6s_v2
  - Standard_NC12s_v2
  - Standard_NC24s_v2
  - Standard_NC24rs_v2
  - Standard_NC4as_T4_v3
  - Standard_NC8as_T4_v3
  - Standard_NC16as_T4_v3
  - Standard_NC64as_T4_v3
  - Standard_ND6s
  - Standard_ND12s
  - Standard_ND24s
  - Standard_ND24rs
  - Standard_ND40rs_v2
  - Standard_ND96asr_v4
  license: apache-2.0
  model_specific_defaults:
    apply_deepspeed: 'true'
    apply_lora: 'true'
    apply_ort: 'true'
  task: fill-mask
version: 10
description: |
  DistilRoBERTa base is a distilled version of the RoBERTa-base model, with 6 layers, 768 dimension, and 12 heads, and 82M parameters, it is faster than RoBERTa-base. The model is primarily intended for fine-tuning on whole sentence-based tasks such as sequence classification, token classification, and question answering but should not be used to generate harmful or alienating content. There is a risk of bias in the generated predictions as it may include harmful stereotypes. It is developed by Victor Sanh, Lysandre Debut, Julien Chaumond and Thomas Wolf of Hugging Face and is licensed under Apache 2.0. Users are encouraged to check out the RoBERTa-base model card for more information. When getting started with the model, it is recommended to use fine-tuned versions on the task that interests you.
  <br>Please Note: This model accepts masks in `<mask>` format. See Sample input for reference.Â 
  > The above summary was generated using ChatGPT. Review the <a href="https://huggingface.co/distilroberta-base" target="_blank">original model card</a> to understand the data used to train the model, evaluation metrics, license, intended uses, limitations and bias before using the model.

  ### Inference samples

  Inference type|Python sample (Notebook)|CLI with YAML
  |--|--|--|
  Real time|<a href="https://aka.ms/azureml-infer-online-sdk-fill-mask" target="_blank">fill-mask-online-endpoint.ipynb</a>|<a href="https://aka.ms/azureml-infer-online-cli-fill-mask" target="_blank">fill-mask-online-endpoint.sh</a>
  Batch |<a href="https://aka.ms/azureml-infer-batch-sdk-fill-mask" target="_blank">fill-mask-batch-endpoint.ipynb</a>| coming soon


  ### Finetuning samples

  Task|Use case|Dataset|Python sample (Notebook)|CLI with YAML
  |--|--|--|--|--|
  Text Classification|Emotion Detection|<a href="https://huggingface.co/datasets/dair-ai/emotion" target="_blank">Emotion</a>|<a href="https://aka.ms/azureml-ft-sdk-emotion-detection" target="_blank">emotion-detection.ipynb</a>|<a href="https://aka.ms/azureml-ft-cli-emotion-detection" target="_blank">emotion-detection.sh</a>
  Token Classification|Named Entity Recognition|<a href="https://huggingface.co/datasets/conll2003" target="_blank">Conll2003</a>|<a href="https://aka.ms/azureml-ft-sdk-token-classification" target="_blank">named-entity-recognition.ipynb</a>|<a href="https://aka.ms/azureml-ft-cli-token-classification" target="_blank">named-entity-recognition.sh</a>
  Question Answering|Extractive Q&A|<a href="https://huggingface.co/datasets/squad" target="_blank">SQUAD (Wikipedia)</a>|<a href="https://aka.ms/azureml-ft-sdk-extractive-qa" target="_blank">extractive-qa.ipynb</a>|<a href="https://aka.ms/azureml-ft-cli-extractive-qa" target="_blank">extractive-qa.sh</a>


  ### Model Evaluation

  Task| Use case| Python sample (Notebook)| CLI with YAML
  |--|--|--|--|
  Fill Mask | Fill Mask | <a href="https://huggingface.co/datasets/rcds/wikipedia-for-mask-filling" target="_blank">rcds/wikipedia-for-mask-filling</a> | <a href="https://aka.ms/azureml-eval-sdk-fill-mask/" target="_blank">evaluate-model-fill-mask.ipynb</a> | <a href="https://aka.ms/azureml-eval-cli-fill-mask/" target="_blank">evaluate-model-fill-mask.yml</a>


  ### Sample inputs and outputs (for real-time inference)

  #### Sample input
  ```json
  {
      "input_data": {
          "input_string": ["Paris is the <mask> of France.", "Today is a <mask> day!"]
      }
  }
  ```

  #### Sample output
  ```json
  [
      {
          "0": "capital"
      },
      {
          "0": "beautiful"
      }
  ]
  ```
